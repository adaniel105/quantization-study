## quanitization-study
Studying quanitization techniques to reduce the computational overhead of training and inference with multi-million/billion parameter models.

Paper Links:

QLoRA: Efficient Finetuning of quantized LLMs - https://arxiv.org/abs/2305.14314

GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection - GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection

