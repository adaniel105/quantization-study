## quanitization-study
Studying quanitization techniques & parameter efficient fine tuning to reduce the computational overhead of training and inference with multi-million/billion parameter models.

quantization techniques:
- overview : https://www.inferless.com/learn/quantization-techniques-demystified-boosting-efficiency-in-large-language-models-llms
- GGUF: https://www.reddit.com/r/LocalLLaMA/comments/1ba55rj/overview_of_gguf_quantization_methods/

## Paper Backlog

QLoRA: Efficient Finetuning of quantized LLMs - https://arxiv.org/abs/2305.14314

GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection - https://arxiv.org/abs/2403.03507

LISA : https://www.alphaxiv.org/abs/2403.17919

